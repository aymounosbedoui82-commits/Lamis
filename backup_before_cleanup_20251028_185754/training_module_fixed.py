# training_module.py - Fixed Version âœ…
"""
Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø°Ø§ØªÙŠ - Ù†Ø³Ø®Ø© Ù…Ø­Ø¯Ø«Ø©
Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ intelligent_agent.py
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import sqlite3
import numpy as np
from typing import List, Tuple
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)


class InteractionDataset(Dataset):
    """Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
    
    def __init__(self, db_path="agent_data.db"):
        self.db_path = db_path
        self.data = self._load_data()
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†ÙˆØ§ÙŠØ§ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
        self.intent_labels = [
            'add_appointment',
            'list_appointments',
            'cancel_appointment',
            'modify_appointment',
            'greeting',
            'thanks',
            'help',
            'check_schedule',
            'check_specific_day',
            'general_query'
        ]
    
    def _load_data(self) -> List[Tuple]:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT user_message, intent, language, feedback
                FROM interactions
                WHERE intent IS NOT NULL AND intent != ''
                ORDER BY timestamp DESC
                LIMIT 10000
            ''')
            
            data = cursor.fetchall()
            conn.close()
            
            logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(data)} ØªÙØ§Ø¹Ù„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            return data
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return []
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        message, intent, language, feedback = self.data[idx]
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ vector Ø¨Ø³ÙŠØ· (ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹)
        # Ù‡Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø©: Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ ÙˆØ¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        words = message.split()
        features = torch.tensor([
            len(message),           # Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ
            len(words),            # Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
            len(set(words)),       # Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©
            1 if language == 'ar' else 0,  # Ø¹Ø±Ø¨ÙŠ
            1 if language == 'fr' else 0,  # ÙØ±Ù†Ø³ÙŠ
            1 if language == 'en' else 0,  # Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
            feedback if feedback else 0    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        ], dtype=torch.float32)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ÙŠØ© Ø¥Ù„Ù‰ Ø±Ù‚Ù…
        if intent in self.intent_labels:
            intent_idx = self.intent_labels.index(intent)
        else:
            intent_idx = len(self.intent_labels) - 1  # general_query
        
        return features, torch.tensor(intent_idx, dtype=torch.long), feedback if feedback else 0


class SimpleIntentClassifier(nn.Module):
    """Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ· Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ÙˆØ§ÙŠØ§"""
    
    def __init__(self, input_size=7, hidden_size=64, num_classes=10):
        super(SimpleIntentClassifier, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.3)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        return x


class AdaptiveLearner:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªÙƒÙŠÙÙŠ"""
    
    def __init__(self, db_path="agent_data.db"):
        self.db_path = db_path
        self.model = SimpleIntentClassifier()
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        self.criterion = nn.CrossEntropyLoss()
        self.training_history = []
    
    def train_epoch(self, dataloader: DataLoader) -> Tuple[float, float]:
        """ØªØ¯Ø±ÙŠØ¨ epoch ÙˆØ§Ø­Ø¯"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for features, labels, feedbacks in dataloader:
            self.optimizer.zero_grad()
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            outputs = self.model(features)
            loss = self.criterion(outputs, labels)
            
            # ØªØ·Ø¨ÙŠÙ‚ ÙˆØ²Ù† Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ø°Ø§Øª feedback Ø¥ÙŠØ¬Ø§Ø¨ÙŠ
            feedbacks_tensor = torch.tensor([f if f else 0 for f in feedbacks], dtype=torch.float32)
            weighted_loss = loss * (1 + feedbacks_tensor.mean() * 0.1)
            
            # Backpropagation
            weighted_loss.backward()
            self.optimizer.step()
            
            total_loss += weighted_loss.item()
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
        
        accuracy = 100 * correct / total if total > 0 else 0
        avg_loss = total_loss / len(dataloader) if len(dataloader) > 0 else 0
        
        return avg_loss, accuracy
    
    def evaluate(self, dataloader: DataLoader) -> Tuple[float, float]:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for features, labels, _ in dataloader:
                outputs = self.model(features)
                loss = self.criterion(outputs, labels)
                total_loss += loss.item()
                
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        accuracy = 100 * correct / total if total > 0 else 0
        avg_loss = total_loss / len(dataloader) if len(dataloader) > 0 else 0
        
        return avg_loss, accuracy
    
    def train(self, epochs=10, batch_size=16, validation_split=0.2):
        """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„"""
        print("\n" + "="*60)
        print("ğŸ§  Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø°ÙƒÙŠ...")
        print("="*60)
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        dataset = InteractionDataset(self.db_path)
        
        if len(dataset) < 10:
            print("\nâŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨!")
            print(f"   Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰: 10 ØªÙØ§Ø¹Ù„Ø§Øª")
            print(f"   Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯: {len(dataset)} ØªÙØ§Ø¹Ù„")
            print("\nğŸ’¡ Ø§Ù„Ø­Ù„:")
            print("   1. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙˆØª Ù„ÙØªØ±Ø© Ø£Ø·ÙˆÙ„")
            print("   2. ØªÙØ§Ø¹Ù„ Ù…Ø¹Ù‡ Ø¨Ø¹Ø¯Ø© Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ©")
            print("   3. Ø¹Ø¯ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ø§Ø­Ù‚Ø§Ù‹")
            return False
        
        print(f"\nğŸ“Š ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(dataset)} ØªÙØ§Ø¹Ù„")
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        train_size = int((1 - validation_split) * len(dataset))
        val_size = len(dataset) - train_size
        train_dataset, val_dataset = torch.utils.data.random_split(
            dataset, [train_size, val_size]
        )
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        
        print(f"   ğŸ“š Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {train_size}")
        print(f"   âœ… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚: {val_size}")
        
        best_val_accuracy = 0
        
        print("\n" + "â”€"*60)
        for epoch in range(epochs):
            train_loss, train_acc = self.train_epoch(train_loader)
            val_loss, val_acc = self.evaluate(val_loader)
            
            print(f"\nğŸ“ Epoch {epoch+1}/{epochs}")
            print(f"   ğŸ‹ï¸ Ø§Ù„ØªØ¯Ø±ÙŠØ¨   â†’ Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%")
            print(f"   âœ… Ø§Ù„ØªØ­Ù‚Ù‚    â†’ Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%")
            
            # Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
            if val_acc > best_val_accuracy:
                best_val_accuracy = val_acc
                self.save_model("best_model.pth")
                print(f"   â­ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬! (Accuracy: {val_acc:.2f}%)")
            
            self.training_history.append({
                'epoch': epoch + 1,
                'train_loss': train_loss,
                'train_acc': train_acc,
                'val_loss': val_loss,
                'val_acc': val_acc
            })
        
        print("\n" + "="*60)
        print(f"ğŸ‰ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨!")
        print(f"â­ Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©: {best_val_accuracy:.2f}%")
        print("="*60)
        
        return True
    
    def save_model(self, path: str):
        """Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        try:
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'training_history': self.training_history
            }, path)
            logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {path}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
    
    def load_model(self, path: str):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        try:
            checkpoint = torch.load(path)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            self.training_history = checkpoint.get('training_history', [])
            logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† {path}")
            return True
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return False
    
    def continuous_learning(self, min_new_interactions=50):
        """Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
        print("\nğŸ”„ ÙØ­Øµ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        cursor.execute('''
            SELECT COUNT(*) FROM interactions 
            WHERE timestamp > datetime('now', '-7 days')
            AND intent IS NOT NULL
        ''')
        
        new_interactions = cursor.fetchone()[0]
        conn.close()
        
        print(f"   ğŸ“Š ØªÙØ§Ø¹Ù„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© (Ø¢Ø®Ø± 7 Ø£ÙŠØ§Ù…): {new_interactions}")
        
        if new_interactions >= min_new_interactions:
            print(f"   âœ… ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨! (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰: {min_new_interactions})")
            print("\nğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±...")
            return self.train(epochs=5, batch_size=16)
        else:
            print(f"   â³ ØºÙŠØ± ÙƒØ§ÙÙŠØ© (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰: {min_new_interactions})")
            print(f"   ğŸ’¡ Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙˆØª Ù„Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            return False


class FeedbackCollector:
    """Ø¬Ù…Ø¹ Ø±Ø¯ÙˆØ¯ Ø§Ù„ÙØ¹Ù„ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¹Ù„Ù…"""
    
    def __init__(self, db_path="agent_data.db"):
        self.db_path = db_path
    
    def add_feedback(self, interaction_id: int, feedback_score: int):
        """Ø¥Ø¶Ø§ÙØ© ØªÙ‚ÙŠÙŠÙ… Ù„Ù„ØªÙØ§Ø¹Ù„ (1-5)"""
        if not 1 <= feedback_score <= 5:
            logger.warning(f"âš ï¸ ØªÙ‚ÙŠÙŠÙ… ØºÙŠØ± ØµØ§Ù„Ø­: {feedback_score} (ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† 1-5)")
            return False
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                UPDATE interactions 
                SET feedback = ? 
                WHERE id = ?
            ''', (feedback_score, interaction_id))
            
            conn.commit()
            conn.close()
            
            logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© ØªÙ‚ÙŠÙŠÙ…: {feedback_score}/5 Ù„Ù„ØªÙØ§Ø¹Ù„ #{interaction_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {e}")
            return False
    
    def get_feedback_statistics(self) -> dict:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø±Ø¯ÙˆØ¯ Ø§Ù„ÙØ¹Ù„"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT 
                    COUNT(*) as total,
                    AVG(feedback) as avg_feedback,
                    COUNT(CASE WHEN feedback >= 4 THEN 1 END) as positive,
                    COUNT(CASE WHEN feedback <= 2 THEN 1 END) as negative
                FROM interactions
                WHERE feedback > 0
            ''')
            
            result = cursor.fetchone()
            conn.close()
            
            if result[0] == 0:
                return {
                    'total_feedbacks': 0,
                    'average_score': 0,
                    'positive_count': 0,
                    'negative_count': 0,
                    'satisfaction_rate': 0
                }
            
            return {
                'total_feedbacks': result[0],
                'average_score': round(result[1], 2) if result[1] else 0,
                'positive_count': result[2],
                'negative_count': result[3],
                'satisfaction_rate': round((result[2] / result[0] * 100), 2) if result[0] > 0 else 0
            }
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}")
            return {}
    
    def analyze_weaknesses(self) -> List[dict]:
        """ØªØ­Ù„ÙŠÙ„ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT intent, language, AVG(feedback) as avg_feedback, COUNT(*) as count
                FROM interactions
                WHERE feedback > 0 AND intent IS NOT NULL
                GROUP BY intent, language
                HAVING count >= 3
                ORDER BY avg_feedback ASC
                LIMIT 10
            ''')
            
            weaknesses = []
            for row in cursor.fetchall():
                weaknesses.append({
                    'intent': row[0],
                    'language': row[1],
                    'avg_feedback': round(row[2], 2),
                    'sample_count': row[3]
                })
            
            conn.close()
            return weaknesses
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
            return []


# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    print("="*60)
    print("ğŸ§  Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø°Ø§ØªÙŠ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ")
    print("="*60)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ØªØ¹Ù„Ù… Ø§Ù„ØªÙƒÙŠÙÙŠ
    learner = AdaptiveLearner()
    
    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    success = learner.train(epochs=10, batch_size=16)
    
    if success:
        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        learner.save_model("trained_model.pth")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø±Ø¯ÙˆØ¯ Ø§Ù„ÙØ¹Ù„
        collector = FeedbackCollector()
        stats = collector.get_feedback_statistics()
        
        if stats['total_feedbacks'] > 0:
            print("\n" + "="*60)
            print("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡:")
            print("="*60)
            print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª: {stats['total_feedbacks']}")
            print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {stats['average_score']}/5")
            print(f"   Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø¶Ø§: {stats['satisfaction_rate']}%")
            print(f"   ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©: {stats['positive_count']}")
            print(f"   ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø³Ù„Ø¨ÙŠØ©: {stats['negative_count']}")
            
            # Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù
            weaknesses = collector.analyze_weaknesses()
            if weaknesses:
                print("\nâš ï¸ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†:")
                for w in weaknesses:
                    print(f"   â€¢ {w['intent']} ({w['language']}): {w['avg_feedback']}/5")
        
        print("\nâœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
    else:
        print("\nâš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ - Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹")